{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-25T14:56:55.069991Z","iopub.execute_input":"2025-06-25T14:56:55.070356Z","iopub.status.idle":"2025-06-25T14:56:55.075870Z","shell.execute_reply.started":"2025-06-25T14:56:55.070332Z","shell.execute_reply":"2025-06-25T14:56:55.075028Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\nos.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\nos.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128,expandable_segments:True\"\nos.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"  # Suppress TensorFlow logs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T14:56:55.076945Z","iopub.execute_input":"2025-06-25T14:56:55.077181Z","iopub.status.idle":"2025-06-25T14:56:55.099850Z","shell.execute_reply.started":"2025-06-25T14:56:55.077163Z","shell.execute_reply":"2025-06-25T14:56:55.099238Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# ───────────────────────────────────────────────────────────────\n# Install -- run once per notebook\n# ───────────────────────────────────────────────────────────────\n!pip install --quiet \\\n    \"transformers>=4.41.0\" peft unsloth accelerate \\\n    datasets evaluate bert-score sacrebleu nltk\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T14:56:55.100965Z","iopub.execute_input":"2025-06-25T14:56:55.101192Z","iopub.status.idle":"2025-06-25T15:00:04.624020Z","shell.execute_reply.started":"2025-06-25T14:56:55.101169Z","shell.execute_reply":"2025-06-25T15:00:04.623266Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.1/47.1 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.6/278.6 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.1/61.1 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.8/375.8 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/31.5 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m865.2/865.2 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.5/156.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m393.1/393.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m73.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.7/897.7 kB\u001b[0m \u001b[31m39.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m571.0/571.0 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.2/200.2 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.2/158.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.6/216.6 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.8/156.8 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.3/201.3 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.7/19.7 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 MB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m95.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.3/128.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m97.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.7/210.7 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\ntorchaudio 2.6.0+cu124 requires torch==2.6.0, but you have torch 2.7.0 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\ngcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\nfastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.7.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# # ─────────────────────────────────────────────────────────────────────────────\n# #  Alpaca evaluation  –  ROUGE | BLEU | Precision | BERTScore\n# # ─────────────────────────────────────────────────────────────────────────────\n# import os, random, torch, nltk, re, pandas as pd\n# from datasets import load_dataset\n# from evaluate  import load as load_metric\n# from transformers import AutoTokenizer, AutoModelForCausalLM\n# from peft import PeftModel\n\n# # ================ Secrets (optional) ========================================\n# HF_TOKEN = None\n# try:\n#     from kaggle_secrets import UserSecretsClient            # noqa: E402\n#     HF_TOKEN = UserSecretsClient().get_secret(\"HF_TOKEN\")\n#     print(\"✅  Hugging Face token retrieved.\")\n# except Exception:\n#     print(\"ℹ️  No HF token found – assuming the models are public.\")\n\n# # ================ Config ====================================================\n# BASE_MODEL_ID    = \"unsloth/mistral-7b-v0.3-bnb-4bit\"\n# ADAPTER_MODEL_ID = \"ParamDev/mistral-7b-v0.3_alpaca\"   # your LoRA\n\n# EVAL_FRACTION      = 0.10          # 10 % of Alpaca for evaluation\n# SEED               = 42\n# MAX_SAMPLES        = 1000          # cap for speed; set None for full\n# MAX_NEW_TOKENS     = 1024\n# TEMPERATURE        = 0.3\n# TOP_P              = 0.9\n# DO_SAMPLE          = True\n\n# DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n# print(f\"🚀  Using device: {DEVICE}\")\n\n# # ================ NLTK (for metrics) =======================================\n# def ensure_nltk():\n#     for res in (\"punkt\", \"wordnet\", \"omw-1.4\"):\n#         try:\n#             nltk.data.find(\n#                 f\"tokenizers/{res}\" if res == \"punkt\" else f\"corpora/{res}\"\n#             )\n#         except LookupError:\n#             nltk.download(res, quiet=True)\n# ensure_nltk()\n\n# # ================ Load Alpaca ==============================================\n# def load_alpaca(eval_frac, cap, seed):\n#     ds = load_dataset(\"tatsu-lab/alpaca\", split=\"train\")\n#     total = len(ds)\n#     eval_size = int(total * eval_frac)\n#     random.seed(seed)\n#     idxs = random.sample(range(total), eval_size)\n#     if cap is not None:\n#         idxs = idxs[:cap]\n#     subset = ds.select(idxs)\n#     print(f\"🔎  Alpaca evaluation subset: {len(subset)} / {total}\")\n#     return subset\n\n# # ================ Model & Tokenizer ========================================\n# def load_model(base_id, adapter_id, token):\n#     try:\n#         tok = AutoTokenizer.from_pretrained(adapter_id, token=token)\n#     except OSError:\n#         tok = AutoTokenizer.from_pretrained(base_id, token=token)\n#     tok.pad_token = tok.eos_token\n\n#     base = AutoModelForCausalLM.from_pretrained(\n#         base_id,\n#         torch_dtype = torch.bfloat16 if DEVICE == \"cuda\" else torch.float32,\n#         device_map  = \"auto\"         if DEVICE == \"cuda\" else None,\n#         token       = token,\n#     )\n\n#     model = PeftModel.from_pretrained(\n#         base, adapter_id, token=token, device_map=\"auto\" if DEVICE == \"cuda\" else None\n#     )\n#     model.eval()\n#     return model, tok\n\n# # ================ Generation ===============================================\n# def generate(prompt, model, tok):\n#     chat = [{\"role\": \"user\", \"content\": prompt}]\n#     ids  = tok.apply_chat_template(chat, tokenize=True,\n#                                    add_generation_prompt=True,\n#                                    return_tensors=\"pt\").to(model.device)\n#     out  = model.generate(\n#         ids,\n#         max_new_tokens = MAX_NEW_TOKENS,\n#         temperature    = TEMPERATURE,\n#         top_p          = TOP_P,\n#         do_sample      = DO_SAMPLE,\n#         pad_token_id   = tok.pad_token_id,\n#     )[0][ids.shape[-1]:]\n#     return tok.decode(out, skip_special_tokens=True).strip()\n\n# # ================ Simple token-level precision =============================\n# tokeniser = re.compile(r\"\\w+\")\n\n# def word_precision(pred, ref):\n#     pred_toks = tokeniser.findall(pred.lower())\n#     ref_toks  = tokeniser.findall(ref.lower())\n#     if not pred_toks:  # avoid div-by-zero\n#         return 0.0\n#     overlap = sum(1 for t in pred_toks if t in ref_toks)\n#     return overlap / len(pred_toks)\n\n# # ================ Main ======================================================\n# def main():\n#     ds = load_alpaca(EVAL_FRACTION, MAX_SAMPLES, SEED)\n\n#     model, tok = load_model(BASE_MODEL_ID, ADAPTER_MODEL_ID, HF_TOKEN)\n\n#     rouge  = load_metric(\"rouge\")\n#     bleu   = load_metric(\"sacrebleu\")\n#     bert   = load_metric(\"bertscore\")\n\n#     preds, refs, refs_bleu, precisions = [], [], [], []\n\n#     for i, ex in enumerate(ds, 1):\n#         prompt    = ex[\"instruction\"]\n#         reference = ex[\"output\"]\n#         pred      = generate(prompt, model, tok)\n\n#         preds.append(pred)\n#         refs.append(reference)\n#         refs_bleu.append([reference])\n#         precisions.append(word_precision(pred, reference))\n\n#         if i <= 3:  # show a few examples\n#             print(f\"\\n—— Example {i} ————————————————\")\n#             print(\"Prompt    :\", prompt[:120].replace(\"\\n\", \" \"))\n#             print(\"Reference :\", reference[:120].replace(\"\\n\", \" \"))\n#             print(\"Generated :\", pred[:120].replace(\"\\n\", \" \"))\n\n#     # ─── ROUGE ──────────────────────────────────────────────────────────────\n#     r = rouge.compute(predictions=preds, references=refs)\n#     print(\"\\n📊  ROUGE\")\n#     for k, v in r.items():\n#         print(f\"  {k:7} : {v*100:5.2f}\")\n\n#     # ─── BLEU (sacrebleu) ───────────────────────────────────────────────────\n#     b = bleu.compute(predictions=preds, references=refs_bleu)\n#     print(\"\\n📊  BLEU\")\n#     print(f\"  Score   : {b['score']:.2f}\")\n\n#     # ─── Simple token precision ────────────────────────────────────────────\n#     tp = sum(precisions) / len(precisions)\n#     print(\"\\n📊  Token Precision (word overlap)\")\n#     print(f\"  Precision : {tp*100:.2f}\")\n\n#     # ─── BERTScore ──────────────────────────────────────────────────────────\n#     bs = bert.compute(predictions=preds, references=refs,\n#                       lang=\"en\", rescale_with_baseline=True)\n#     P = sum(bs[\"precision\"]) / len(bs[\"precision\"])\n#     R = sum(bs[\"recall\"])    / len(bs[\"recall\"])\n#     F = sum(bs[\"f1\"])        / len(bs[\"f1\"])\n#     print(\"\\n📊  BERTScore (rescaled)\")\n#     print(f\"  Precision : {P*100:.2f}\")\n#     print(f\"  Recall    : {R*100:.2f}\")\n#     print(f\"  F1        : {F*100:.2f}\")\n\n#     print(\"\\n✅  Evaluation complete.\")\n\n# if __name__ == \"__main__\":\n#     main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:00:04.625680Z","iopub.execute_input":"2025-06-25T15:00:04.625930Z","iopub.status.idle":"2025-06-25T15:00:04.633340Z","shell.execute_reply.started":"2025-06-25T15:00:04.625910Z","shell.execute_reply":"2025-06-25T15:00:04.632466Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# ───────────────────────────────────────────────────────────────\n#  Evaluate UnsLoTH-LoRA model on yahma/alpaca-cleaned\n#  Metrics: ROUGE | BLEU | word-precision | BERTScore\n# ───────────────────────────────────────────────────────────────\nimport os, random, re, torch, nltk\nfrom datasets import load_dataset\nfrom evaluate import load as load_metric\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom peft import PeftModel\n\n# ----------------------------\n# Secrets (optional, for HF Hub)\n# ----------------------------\nHF_TOKEN = None\ntry:\n    from kaggle_secrets import UserSecretsClient            # noqa: E402\n    HF_TOKEN = UserSecretsClient().get_secret(\"HF_TOKEN\")\n    print(\"✅  Hugging Face token retrieved.\")\nexcept Exception:\n    print(\"ℹ️  No HF token found – assuming public models.\")\n\n# ----------------------------\n# Config\n# ----------------------------\nBASE_MODEL_ID    = \"unsloth/mistral-7b-v0.3-bnb-4bit\"\nADAPTER_MODEL_ID = \"ParamDev/mistral-7b-v0.3_alpaca\"     # your LoRA adapter\n\nEVAL_FRACTION   = 0.10    # 10 % random slice of Alpaca-cleaned\nMAX_SAMPLES     = 1000    # cap for speed.  Set None to use the full slice\nSEED            = 42\nMAX_NEW_TOKENS  = 256\nTEMPERATURE     = 0.3\nTOP_P           = 0.9\nDO_SAMPLE       = True\n\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(f\"🚀  Using device: {DEVICE}\")\n\n# ----------------------------\n# NLTK resources (ROUGE / BLEU helper)\n# ----------------------------\nfor res in (\"punkt\", \"wordnet\", \"omw-1.4\"):\n    try:\n        path = (\"tokenizers/\" if res == \"punkt\" else \"corpora/\") + res\n        nltk.data.find(path)\n    except LookupError:\n        nltk.download(res, quiet=True)\n\n# ----------------------------\n# Data\n# ----------------------------\ndef load_alpaca_cleaned(frac, cap, seed):\n    ds = load_dataset(\"yahma/alpaca-cleaned\", split=\"train\")\n    total = len(ds)\n    eval_size = int(total * frac)\n    random.seed(seed)\n    idxs = random.sample(range(total), eval_size)\n    if cap is not None:\n        idxs = idxs[:cap]\n    sub = ds.select(idxs)\n    print(f\"🔎  Evaluation subset: {len(sub)} / {total}\")\n    return sub\n\n# ----------------------------\n# Model & tokenizer\n# ----------------------------\ndef load_model(base_id, adapter_id, token):\n    try:\n        tok = AutoTokenizer.from_pretrained(adapter_id, token=token)\n    except OSError:\n        tok = AutoTokenizer.from_pretrained(base_id, token=token)\n    tok.pad_token = tok.eos_token\n\n    base = AutoModelForCausalLM.from_pretrained(\n        base_id,\n        torch_dtype = torch.bfloat16 if DEVICE == \"cuda\" else torch.float32,\n        device_map  = \"auto\" if DEVICE == \"cuda\" else None,\n        token       = token,\n    )\n\n    model = PeftModel.from_pretrained(\n        base, adapter_id, token=token, device_map=\"auto\" if DEVICE == \"cuda\" else None\n    )\n    model.eval()\n    return model, tok\n\n# ----------------------------\n# Generation\n# ----------------------------\ndef generate_response(prompt, model, tok):\n    chat = [{\"role\": \"user\", \"content\": prompt}]\n    ids  = tok.apply_chat_template(chat, tokenize=True,\n                                   add_generation_prompt=True,\n                                   return_tensors=\"pt\").to(model.device)\n    out  = model.generate(\n        ids,\n        max_new_tokens = MAX_NEW_TOKENS,\n        temperature    = TEMPERATURE,\n        top_p          = TOP_P,\n        do_sample      = DO_SAMPLE,\n        pad_token_id   = tok.pad_token_id,\n    )[0][ids.shape[-1]:]\n    return tok.decode(out, skip_special_tokens=True).strip()\n\n# ----------------------------\n# Lexical precision (word-overlap)\n# ----------------------------\n_tokeniser = re.compile(r\"\\w+\")\ndef word_precision(pred, ref):\n    pt = _tokeniser.findall(pred.lower())\n    rt = _tokeniser.findall(ref.lower())\n    return 0.0 if not pt else sum(1 for t in pt if t in rt) / len(pt)\n\n# ----------------------------\n# Main\n# ----------------------------\ndef main():\n    ds = load_alpaca_cleaned(EVAL_FRACTION, MAX_SAMPLES, SEED)\n    model, tok = load_model(BASE_MODEL_ID, ADAPTER_MODEL_ID, HF_TOKEN)\n\n    rouge = load_metric(\"rouge\")\n    bleu  = load_metric(\"sacrebleu\")\n    bert  = load_metric(\"bertscore\")\n\n    preds, refs, refs_bleu, precs = [], [], [], []\n\n    for i, ex in enumerate(ds, 1):\n        # Re-create the same *semantic* prompt the model was trained on\n        # (notice we do NOT append the target/output)\n        if ex[\"input\"]:\n            prompt = f\"{ex['instruction']}\\n{ex['input']}\"\n        else:\n            prompt = ex[\"instruction\"]\n\n        reference = ex[\"output\"]\n        pred      = generate_response(prompt, model, tok)\n\n        preds.append(pred)\n        refs.append(reference)\n        refs_bleu.append([reference])\n        precs.append(word_precision(pred, reference))\n\n        if i <= 3:   # quick peek\n            print(f\"\\n—— Example {i} ————————————————\")\n            print(\"Prompt    :\", prompt[:120].replace('\\n', ' '))\n            print(\"Reference :\", reference[:120].replace('\\n', ' '))\n            print(\"Generated :\", pred[:120].replace('\\n', ' '))\n\n    # ---------- metrics ----------\n    r = rouge.compute(predictions=preds, references=refs)\n    print(\"\\n📊  ROUGE\")\n    for k, v in r.items():\n        print(f\"  {k:7} : {v*100:5.2f}\")\n\n    b = bleu.compute(predictions=preds, references=refs_bleu)\n    print(\"\\n📊  BLEU (sacrebleu)\")\n    print(f\"  Score   : {b['score']:.2f}\")\n\n    tp = sum(precs) / len(precs)\n    print(\"\\n📊  Word Precision\")\n    print(f\"  Precision : {tp*100:.2f}\")\n\n    bs = bert.compute(predictions=preds, references=refs,\n                      lang=\"en\", rescale_with_baseline=True)\n    P = sum(bs[\"precision\"]) / len(bs[\"precision\"])\n    R = sum(bs[\"recall\"])    / len(bs[\"recall\"])\n    F = sum(bs[\"f1\"])        / len(bs[\"f1\"])\n    print(\"\\n📊  BERTScore (rescaled)\")\n    print(f\"  Precision : {P*100:.2f}\")\n    print(f\"  Recall    : {R*100:.2f}\")\n    print(f\"  F1        : {F*100:.2f}\")\n\n    print(\"\\n✅  Evaluation complete.\")\n\nif __name__ == \"__main__\":\n    main()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-25T15:00:04.634167Z","iopub.execute_input":"2025-06-25T15:00:04.634457Z","iopub.status.idle":"2025-06-25T15:00:05.325355Z","shell.execute_reply.started":"2025-06-25T15:00:04.634433Z","shell.execute_reply":"2025-06-25T15:00:05.324211Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/1952571193.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mevaluate\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mload_metric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpeft\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPeftModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mevaluation_suite\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEvaluationSuite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m from .evaluator import (\n\u001b[1;32m     31\u001b[0m     \u001b[0mAudioClassificationEvaluator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/evaluation_suite/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluator\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloading\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mevaluation_module_factory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/evaluate/evaluator/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSUPPORTED_TASKS\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mSUPPORTED_PIPELINE_TASKS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTASK_ALIASES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipelines\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcheck_task\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcheck_pipeline_task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/pipelines/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_module_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_class_from_dynamic_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPreTrainedFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_processing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBaseImageProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfiguration_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoConfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_extraction_auto\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFEATURE_EXTRACTOR_MAPPING\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoFeatureExtractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_processing_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_processing_base\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBatchFeature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mImageProcessingMixin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_transforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcenter_crop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrescale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mimage_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_image_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_transforms.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m from .image_utils import (\n\u001b[0m\u001b[1;32m     22\u001b[0m     \u001b[0mChannelDimension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mImageInput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/image_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mis_torchvision_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtorchvision_io\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mInterpolationMode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# .extensions) before entering _meta_registrations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mextension\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_HAS_OPS\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_meta_registrations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutils\u001b[0m  \u001b[0;31m# usort:skip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torchvision/_meta_registrations.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlibrary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_fake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"torchvision::nms\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmeta_nms\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miou_threshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf\"boxes should be a 2d tensor, got {dets.dim()}D\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/library.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0mdevice_types\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"CompositeExplicitAutograd\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable_dynamo\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/library.py\u001b[0m in \u001b[0;36m_register_fake\u001b[0;34m(self, op_name, fn, _stacklevel)\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;31m# Can be none if you call register_fake from somewhere there isn't a module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \u001b[0;31m# (e.g. __main__)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mcaller_module_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcaller_module\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcaller_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;31m# TODO(rzou): We're gonna need to stage this change with torchvision,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/_library/fake_impl.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, func, source)\u001b[0m\n\u001b[1;32m     29\u001b[0m                 \u001b[0;34mf\"{self.kernel.source}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             )\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch_has_kernel_for_dispatch_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Meta\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             raise RuntimeError(\n\u001b[1;32m     33\u001b[0m                 \u001b[0;34mf\"register_fake(...): the operator {self.qualname} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: operator torchvision::nms does not exist"],"ename":"RuntimeError","evalue":"operator torchvision::nms does not exist","output_type":"error"}],"execution_count":13}]}